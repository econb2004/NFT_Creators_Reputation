import pandas as pd
from sklearn.ensemble import RandomForestRegressor

# Load your hypothetical dataset
# Replace this with your actual data loading code
# Make sure to include all the relevant features and the target variable (Creator Reputation)
data = {
   CSV FILE
}

df = pd.DataFrame(data)

# Convert categorical variables to numerical using one-hot encoding
df_encoded = pd.get_dummies(df[['Provenance', 'Community Engagement', 'Technological Innovation', 'AI Factors', 'Accounting Factors', 'Legal Factors']])

# Concatenate numerical features with one-hot encoded features
X = pd.concat([df[['Scarcity', 'Utility']], df_encoded], axis=1)

# Target variable
y = df['CR']

# Train a Random Forest model
rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X, y)

# Extract feature importances
feature_importances = rf_model.feature_importances_

# Create a DataFrame to display feature importances
feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})
feature_importance_df.sort_values(by='Importance', ascending=False, inplace=True)

# Display the feature importances
print(feature_importance_df)
